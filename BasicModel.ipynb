{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBxeq/iok0OHzLbQfVvK8X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akkasi/EnglishToGerman-Translator/blob/master/BasicModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UETHhiqaus3e"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!pip install  torchtext==0.9.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "5ruJisE4wBTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility"
      ],
      "metadata": {
        "id": "dPhr4PeV1lXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "dbepyjUh09Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to Prepare Data"
      ],
      "metadata": {
        "id": "3OdTg2-B1zSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_de(text):\n",
        "\n",
        "  ''' Tokenize the German text into tokens. It can be replaced by any other type of tokenization.\n",
        "  '''\n",
        "\n",
        "  return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "\n",
        "  ''' Tokenize the English text into tokens. It can be replaced by any other type of tokenization.\n",
        "  '''\n",
        "\n",
        "  return [tok.text for tok in spacy_de.tokenizer(text)]"
      ],
      "metadata": {
        "id": "ucNxRyAb169r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "LJ_pWtfo4QJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Source = Field(sequential=True, tokenize=tokenize_de,\n",
        "               init_token='<SOS>',eos_token='<EOS>',\n",
        "               use_vocab=True,unk_token='<unk>',\n",
        "               lower=True)\n",
        "Target = Field(sequential=True, tokenize=tokenize_en,\n",
        "               init_token='<SOS>',eos_token='<EOS>',\n",
        "               use_vocab=True,unk_token='<unk>',\n",
        "               lower=True)\n",
        "train, validation, test = Multi30k.splits(exts=('.en','.de'),fields=(Source, Target)) ## To change the source and target, it is enough to change the order of extensions"
      ],
      "metadata": {
        "id": "ZIRl52nq4Uk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Investigation and Build the Vocabularies"
      ],
      "metadata": {
        "id": "Ijj9mINt7xZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training samples: {len(train.examples)}')\n",
        "print(f'Number of validation samples: {len(validation.examples)}')\n",
        "print(f'Number of test samples: {len(test.examples)}')\n",
        "\n",
        "print(train.examples[0])\n",
        "print(vars(train.examples[0]))\n",
        "\n",
        "Source.build_vocab(train,min_freq=2,max_size=10000)\n",
        "Target.build_vocab(train, min_freq=2,max_size=10000)\n",
        "\n",
        "print(f'Number of unique tokens in Germany is: {len(Source.vocab)}')\n",
        "print(f'Number of unique tokens in English is: {len(Target.vocab)}')\n",
        "\n"
      ],
      "metadata": {
        "id": "TwX0ix8s761Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters and Data Loaders"
      ],
      "metadata": {
        "id": "AfiH7qNz92xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unicodedata import bidirectional\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 128\n",
        "input_dim = len(Source.vocab)\n",
        "output_dim = len(Target.vocab)\n",
        "enc_embd_dim = 300\n",
        "dec_embd_dim = 300\n",
        "hid_dim = 1024\n",
        "n_layers = 2\n",
        "enc_dropout_p = 0.5\n",
        "dec_dropout_p = 0.5\n",
        "learning_rate = 0.001\n",
        "n_epochs = 20\n",
        "clip = 1\n",
        "bidirectional = False\n",
        "writer = SummaryWriter(f'runs/loss_plot')\n",
        "sytep = 0\n",
        "train_iter, validation_iter, test_iter = BucketIterator.splits((train,validation,test),\n",
        "                                                               batch_size=batch_size,\n",
        "                                                               sort_within_batch = True,\n",
        "                                                               sort_key = lambda x:len(x.src),\n",
        "                                                               device=device)\n"
      ],
      "metadata": {
        "id": "P_FLG7ED95zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "CGoDTn_jBP2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout_p, bidirectional):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim,emb_dim)\n",
        "\n",
        "    self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout_p, bidirectional=bidirectional)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    # x shape = (x len, batch_size)\n",
        "\n",
        "    embedded = self.dropout(self.embedding(x))\n",
        "\n",
        "    #embeded sahpe = (x len, batch_size, emb_dim)\n",
        "\n",
        "    outputs, (hidden,cell) = self.rnn(embedded)\n",
        "\n",
        "    # outputs shape = (x len, batch_size, hid_dim*bidirections)\n",
        "    #hidden shape = (n_layers * directions, batch_size, hid_dim)\n",
        "    #cell shape = (n_layers * directions, batch_size, hid_dim)\n",
        "\n",
        "    return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, output_dim, embd_dim, hid_dim, n_layers, dropout_p):\n",
        "      super().__init__()\n",
        "\n",
        "      self.output_dim = output_dim\n",
        "      self.hid_dim = hid_dim\n",
        "      self.n_layers = n_layers\n",
        "      \n",
        "      self.embeddig = nn.Embedding(output_dim, embd_dim)\n",
        "\n",
        "      self.rnn = nn.LSTM(embd_dim, hid_dim, n_layers, dropout=dropout_p)\n",
        "\n",
        "      self.fc_out = nn.Linear(hid_dim,output_dim) # if hid_dim *2 if bidirection = True\n",
        "\n",
        "      self.dropout = nn.Dropout(dropout_p)\n",
        "    \n",
        "\n",
        "  def forward(self, input, hidden, cell):\n",
        "\n",
        "    # input shape = (batch_size)\n",
        "    #hidden shape = (n_layers * directions, batch_size, hid_dim)\n",
        "    #cell shape = (n_layers * directions, batch_size, hid_dim)\n",
        "\n",
        "    #In decoder we cannot use bidirectional rnn so that:\n",
        "    #hidden shape = (n_layuers, batch_size, hid_dim)\n",
        "    #cell shape = (n_layuers, batch_size, hid_dim)\n",
        "\n",
        "    input = input.unsqueeze(0)\n",
        "    #input shape = (1, batch_size)\n",
        "\n",
        "    embedded = self.dropout(self.embeddig(input))\n",
        "    #embedded shape = (1, batch_size, embd_dim)\n",
        "\n",
        "    output,(hidden,cell) = self.rnn(embedded, (hidden,cell))\n",
        "    #output shape = (1,seq len, batch_size, hid_dim* directions)\n",
        "    #hidden shape = (n_layers*directions, batch_size, hid_dim)\n",
        "    #cell shape = (n_layers*directions, batch_size, hid_dim)\n",
        "    # In decoder we must use one directional LSTM\n",
        "\n",
        "    prediction = self.fc_out(output.squeeze(0))\n",
        "    #prediction shape = (batch_size, output_dim)\n",
        "\n",
        "    return prediction, hidden, cell\n",
        "\n",
        "class BasicSeq2Seq(nn.Module):\n",
        "  def __init__(self,encoder, decoder):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "    assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be same!\"\n",
        "    assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have the same number of layers!\"\n",
        "\n",
        "  def forward(self,source,target, teacher_forcing_ratio = 0.5):\n",
        "    #source shape = (source len, batch_size)\n",
        "    #traget shape = (target len, batch_size)\n",
        "\n",
        "    batch_size = target.shape[1]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = self.decoder.output_dim\n",
        "    \n",
        "    #tensor to store decoder outputs\n",
        "    outputs = torch.zeros(target_len,batch_size,target_vocab_size).to(device)\n",
        "\n",
        "    #last hidden state of the encoder is used as the initial hidden stae of the decoder\n",
        "    hidden, cell = self.encoder(source)\n",
        "\n",
        "    #first input to the decoder is the <sos> token\n",
        "    input = target[0,:]\n",
        "\n",
        "    for t in range(1, target_len):\n",
        "\n",
        "      #insert input token embedding, previous hidden and previous cell state\n",
        "      # receive output tensor (predictions) and new hidden and cell states\n",
        "\n",
        "      output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "      #place predictions in a tensor holding predictions for each token\n",
        "      outputs[t] = output\n",
        "\n",
        "      #decide if we are going to use teacher forcing or not\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "      #get the highest predicted token from our predictions\n",
        "\n",
        "      top = output.argmax(1)\n",
        "\n",
        "      #if teacher forcing, use actrual next token as next input\n",
        "      #if not, use predicted token\n",
        "      input = target[t] if teacher_force else top\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "SGEzayGyBUUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "CsuKGNDNyH_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "fvGVdQYnZW0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(input_dim, enc_embd_dim, hid_dim, n_layers, enc_dropout_p, bidirectional).to(device)\n",
        "decoder = Decoder(output_dim,dec_embd_dim,hid_dim,n_layers,dec_dropout_p).to(device)\n",
        "\n",
        "model = BasicSeq2Seq(encoder, decoder).to(device)"
      ],
      "metadata": {
        "id": "n3m-aTT5ZZFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight Initialization"
      ],
      "metadata": {
        "id": "_C1xzdJhakTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weight(m):\n",
        "  for name,param in m.named_parameters():\n",
        "    nn.init.uniform_(param.data, -0.05,0.05)\n",
        "model.apply(init_weight)"
      ],
      "metadata": {
        "id": "jtwpb3D-aofu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Number of trainable parameters in model"
      ],
      "metadata": {
        "id": "2SZvCIEvbMs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model)}, trainable parameters.')"
      ],
      "metadata": {
        "id": "bXTmHKZ0bVOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Optimizer and Loss functions**"
      ],
      "metadata": {
        "id": "_BPpA9eJb1wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "Target_pad_index = Target.vocab.stoi[Target.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=Target_pad_index)"
      ],
      "metadata": {
        "id": "waY-ZG6ob-oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train and Evaluation functions**"
      ],
      "metadata": {
        "id": "IQ0ELsAycyL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iterator, optimizer, criterion,clip):\n",
        "\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  for i,batch in enumerate(iterator):\n",
        "    source = batch.src \n",
        "    target = batch.trg \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(source,target)\n",
        "\n",
        "    # target shape = (target len, batch_size)\n",
        "    # output shape = (target len, batch_size, output_dim)\n",
        "    output_dim = output.shape[-1]\n",
        "\n",
        "    output = output[1:].view(-1, output_dim)\n",
        "    target = target[1:].view(-1)\n",
        "\n",
        "    #targe shape = (target len -1 * batch size)\n",
        "    #output shape = (target len -1 * batch_size, poutput_dim)\n",
        "\n",
        "    loss = criterion(output,target)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    writer.add_scalar('Training loss',loss,global_step=step)\n",
        "    step +=1\n",
        "    return epoch_loss/ len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  model.eval()\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(iterator):\n",
        "      source = batch.src\n",
        "      target = batch.trg\n",
        "\n",
        "      output = model(source, target)\n",
        "\n",
        "      output_dim = output.shape[-1]\n",
        "\n",
        "      output = output[1:].view(-1,output_dim)\n",
        "      target = target[1:].view(-1)\n",
        "\n",
        "      loss = criterion(output,target)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      return epoch_loss/len(iterator)\n",
        "\n",
        "\n",
        "def translate_sentence(model, sentence, source, target, device, max_lenght=50):\n",
        "  model.eval()\n",
        "  if type(sentence) == str:\n",
        "    tokens = [tok.text.lower() for tok in spacy_en(sentence)]\n",
        "  else:\n",
        "    tokens = [token.lower() for token in sentence]\n",
        "\n",
        "  tokens.insert(0,source.init_token)\n",
        "  tokens.append(source.eos_token)\n",
        "\n",
        "  text_to_indices = [source.vocab.stoi[token] for token in tokens]\n",
        "  sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    hidden,cell = model.encoder(sentence_tensor)\n",
        "\n",
        "  outputs = [target.vocab.stoi[target.pad_token]]\n",
        "\n",
        "  for _ in range(max_lenght):\n",
        "    previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output, hidden,cell = model.decoder(previous_word,hidden, cell)\n",
        "      best_guess = output.argmax(1).item()\n",
        "    outputs.append(best_guess)\n",
        "\n",
        "    if best_guess == target.vocab.stoi[target.eos_token]:\n",
        "      break\n",
        "    \n",
        "  translated_sentence = [target.vocab.itos[idx] for idx in outputs]\n",
        "  model.train()\n",
        "  return translated_sentence[1:]\n",
        "\n",
        "## Function to tell how long an epoch takes\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs\n"
      ],
      "metadata": {
        "id": "iqlJJUEVc3dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "nXOIySx9k8uG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AWGOCsKGuQ9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "step = 0\n",
        "for epoch in range(n_epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss = train(model, train_iter, optimizer, criterion, clip)\n",
        "  valid_loss = evaluate(model, validation_iter, criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_sec = epoch_time(start_time,end_time)\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'BasicSeq2Se.pt')\n",
        "  print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_sec}s ')\n",
        "  print(f'\\t Train loss: {train_loss: .3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "  print(f'\\t Val loss: {valid_loss: .3f} | Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "xaQNRYTxlKHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model"
      ],
      "metadata": {
        "id": "-8yRxRF7njG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('BasicSeq2Se.pt'))\n",
        "test_loss = evaluate(model,test_iter,criterion)\n",
        "print(f'\\t Test loss: {valid_loss: .3f} | Test. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "Fs7O2PmJnlMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translate a sentence"
      ],
      "metadata": {
        "id": "KwXQz_v-XOwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Sentence = 'I will go to school with my friends.'\n",
        "print(translate_sentence(model,Sentence,Source, Target, device))"
      ],
      "metadata": {
        "id": "uDLrb1VoXSdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}